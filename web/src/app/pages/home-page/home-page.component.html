<div class="flex flex-col items-center min-h-fit bg-white pt-4">
  <h1 class="text-3xl font-bold mb-4 text-center">
    Video Stabilizer
  </h1>
  <div class="window md:w-11/12 sm:w-full flex-grow mx-auto bg-orange-50 rounded-xl sm:mx-4 md:mx-0">
    <app-upload-component></app-upload-component> 
    <div *ngIf="!webSocketService.start_processing">
      <div class="flex flex-col md:flex-grow md:overflow-hidden rounded-lg bg-white p-6 shadow-xl sm:mx-6 md:mx-10 mb-10 mt-6">
        <div>
          <div class="text-xl font-medium text-black text-center pb-6">Description</div>
          <p class="text-gray-500">This application uses a <b>three-step block</b> matching algorithm for motion estimation as part of a video stabilization process. It involves dividing the video frames into <b>macroblocks</b> and comparing these blocks to nearby frames. <b>Motion vectors</b> are then created that model the movement of the macroblocks. 
            <b>Global motion vectors</b> are then obtained by  averaging the motion vectors of the macroblocks, frame by frame.</p>
          <p class="text-gray-500">In the <b>motion filtering</b> phase, the <b>Frame Position Smoothing</b> method is used. It calculates a <b>corrective motion vector</b> based on the difference between the <b>actual</b> and <b>estimated positions</b> of a point in a frame. The estimated position is obtained by applying a <b>Fourier transform</b> on the position variation of a point over time and using a <b>low pass filter</b>.</p>
          <p class="text-gray-500">In the <b>post-processing</b> stage, the frames are <b>cropped</b> to produce a stable video output.</p>
          <p class="text-gray-500"> The parameters:</p>
            <ul class="text-gray-500 list-disc pl-5 pb-5">
              <li>Block Size and Search Range are related to the motion estimation process:
                <ul class="list-disc pl-5">
                  <li>
                    <b>Block Size</b> refers to the size of the macroblocks into which the frames are divided.
                  </li>
                  <li>
                    <b>Search Range</b> is a measure of potential motion, and a larger value indicates a larger potential motion and a higher possibility for finding a good match.
                    So larger value should be used if jitter is pretty strong.
                  </li>
                </ul>
              </li>
              <li><b>Filter Intensity</b> is sigma correlated because FPS use a gaussian filter LPF to reduce high frequencies, larger value means stronger filtering.</li>
              <li><b>Post-processing crop</b> let you choose to crop or not the processed video, not cropped video means you get black border on your result.</li>
            </ul>
            <hr>
          <p class="text-gray-500 pt-6"><b>NB:</b> Accepted file type are .avi/.MOV/.mp4. Preview only works with .mp4 file due to browser video implementation, but the app can sure process .avi and .MOV too, no preview are provider for them.</p>
        </div>
      </div>      
    </div> 
    <div *ngIf="webSocketService.start_processing" class="flex flex-col md:flex-row mt-8 w-full h-full sm:px-8 md:px-0 mb-8">
      <div class="flex flex-col md:flex-grow rounded-lg bg-white p-6 w-full md:w-1/3 h-full md:mr-5 md:rounded-l-none shadow-trb">
        <app-processing-component class="flex-grow"></app-processing-component>
      </div>
      <div class="flex flex-col md:flex-grow rounded-lg bg-white p-6 md:w-2/3 md:ml-5 md:rounded-r-none shadow-tlb sm:mt-8 md:mt-0">
        <app-stats-download class="flex-grow"></app-stats-download>
      </div>
    </div> 
          
  </div>
  
</div>
<app-footer></app-footer>

