<div class="flex items-center flex-col min-h-fit pt-4 bg-white">
  <h1 class="text-center font-bold text-3xl mb-4">
    Video Stabilizer
  </h1>
  <div class="w-11/12 mx-auto flex-grow rounded-xl bg-orange-50 sm:mx-4 md:mx-0 window">
    <app-upload-component></app-upload-component> 
    <div *ngIf="!webSocketService.start_processing">
      <div class="mx-3 sm:mx-7 lg:mx-10 p-6 mb-10 mt-6 rounded-lg bg-white shadow-xl flex flex-col md:flex-grow md:overflow-hidden">
        <div class="lg:mx-3">
          <div class="pb-6 text-center font-medium text-xl text-black">What is this App?</div>
          <p class="text-gray-500">This application is a tool designed for video stabilization. It uses the power of motion estimation, motion filtering, and post-processing to achieve this task. The process is carried out in a series of stages, each of which is outlined below:</p>
          
          <div class="pb-2 pt-1 text-left font-medium text-lg text-black">Motion Estimation</div>
          <p class="text-gray-500">The application employs two primary techniques for motion estimation: the <b>three-step search</b> block matching algorithm and the <b>sparse optical flow</b>. </p>
          <p class="text-gray-500">In the context of <b>block matching</b>, frames from the video are divided into <b>macroblocks</b>, which are then compared with nearby frames. This process generates motion vectors that represent the movement of these macroblocks. By <b>averaging</b> these vectors on a frame-by-frame basis, <b>global motion vectors</b> are obtained.</p>
          <p class="text-gray-500">In the context of <b>sparse optical flow</b>, the application utilizes the <b>Shi-Tomasi Corner Detector</b>, an optimized version of the Harris Corner Detector, to identify <b>points of interest</b> within the frames. These points, referred to as features, are tracked across consecutive frames using the <b>Lucas-Kanade</b> method. This method, which assumes that all points within a small neighborhood move similarly, computes the motion of these features. The result is a set of motion vectors that represents the apparent movement of these features between frames. Similar to the block matching approach, these vectors are <b>averaged</b> on a frame-by-frame basis to produce <b>global motion vectors</b>.</p>

          <div class="pb-2 pt-1 text-left font-medium text-lg text-black">Motion Filtering</div>
          <p class="text-gray-500">In the phase of motion filtering, a method known as <b>Frame Position Smoothing (FPS)</b> is used. This method calculates a corrective motion vector based on the difference between the actual and estimated positions of a point in a frame. The estimated position is obtained by applying a <b>Fourier transform</b> to the position variation of a point over time and using a <b>low-pass filter</b>.</p>
          
          <div class="pb-2 pt-1 text-left font-medium text-lg text-black">Post-Processing</div>
          <p class="text-gray-500">The final stage of the process involves post-processing, during which the frames are cropped to produce a stable video output.</p>
          
          <div class="pb-2 pt-1 text-left font-medium text-lg text-black">Parameters</div>
          <p class="text-gray-500"> The application provides several parameters for customization:</p>
          <ul class="text-gray-500 list-disc pl-5 pb-5">
            <li>The parameters Block Size and Search Range are related to the motion estimation process:
              <ul class="list-disc pl-5">
                <li>
                  <b>Block Size</b> refers to the size of the macroblocks into which the frames are divided. Lower values result in longer processing times.
                </li>
                <li>
                  <b>Search Range</b> represents the potential range of motion. Larger values suggest greater potential motion and a higher likelihood of finding a suitable match. It is recommended to use larger values when dealing with particularly strong jitter.
                </li>
              </ul>
            </li>
            <li><b>Filter Intensity</b> is associated with the sigma of the Gaussian filter used in the FPS method for reducing high frequencies. A larger value results in more robust filtering.</li>
            <li><b>Post-processing Crop</b> gives users the choice to crop the processed video. Choosing not to crop the video can lead to black borders in the output.</li>
            <li><b>Compare Motion</b> enables users to compare the original cropped video with the smoothed cropped video by using motion estimation. This provides statistics comparing the jitter in both videos. Be aware that this option may result in additional processing time.</li>
          </ul>
          
          <hr>
          <p class="text-gray-500 pt-6"><b>Note:</b> The application accepts .avi, .MOV, and .mp4 file types. However, due to browser video implementation, only .mp4 and .MOV files can be previewed. .avi files do not support preview.</p>
          </div>        
        </div>

      </div> 
      <div *ngIf="webSocketService.start_processing" class="mt-8 mb-8 w-full h-full sm:px-8 lg:px-0 flex flex-col lg:flex-row">
        <div class="p-6 mx-3 mb-6 sm:mx-0 lg:mb-0 lg:w-1/3 h-full lg:mr-5 shadow-trb rounded-lg bg-white flex flex-col lg:flex-grow lg:rounded-l-none stats-inverted-border-left">
          <app-processing-component class="flex-grow"></app-processing-component>
        </div>
        <div class="p-6 mt-2 mx-3 sm:mx-0 lg:mt-0 lg:w-2/3 lg:ml-5 shadow-tlb rounded-lg bg-white flex flex-col lg:flex-grow lg:rounded-r-none stats-inverted-border-right">
          <app-stats-download class="flex-grow"></app-stats-download>
        </div>
      </div> 
    </div>
  </div>
  <app-footer></app-footer>

